---
layout: post
title: "What's it takes to be a Data Scientists"
description: "Notebook Explore the skills, Education and Tools used by a Data Scientist. Its the Kaggle-annual-Ml-and-DS-Survey-Competition"
output: html_document
date: "2021-01-04"
category: r
tags: [r, kaggle, tidyverse]
comments: true
editor_options: 
  chunk_output_type: console
---







{% highlight r %}
survey <- read_csv("../_data/kaggle_survey_2020_responses.csv")
dim(survey) # dimension of data (rows  columns)
{% endhighlight %}



{% highlight text %}
## [1] 20037   355
{% endhighlight %}



{% highlight r %}
#skimr::skim(survey) # insight of data
{% endhighlight %}

columns represents answer to specific questions and some questions have multiple answers so they have more than one column for representation.

We can merge the columns which represents multi-choice questions for clarity.

## 1. Data Wrangling


{% highlight r %}
# merge columns which represents multi-choice questions.
merge_cols <- function(survey) {
  survey <- survey %>%
     unite("Q7",Q7_Part_1:Q7_OTHER, 
          sep = "," ,
          na.rm = TRUE) %>%
    unite("Q9",Q9_Part_1:Q9_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q10", Q10_Part_1:Q10_OTHER,
           sep = ",",
           na.rm = TRUE) %>%
    unite("Q12", Q12_Part_1:Q12_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q14", Q14_Part_1:Q14_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q16", Q16_Part_1:Q16_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q17", Q17_Part_1:Q17_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q18", Q18_Part_1:Q18_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q19", Q19_Part_1:Q19_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q23", Q23_Part_1:Q23_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q26A", Q26_A_Part_1:Q26_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q26B", Q26_B_Part_1:Q26_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q27A", Q27_A_Part_1:Q27_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q27B", Q27_B_Part_1:Q27_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q28A", Q28_A_Part_1:Q28_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q28B", Q28_B_Part_1:Q28_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q29A", Q29_A_Part_1:Q29_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q29B", Q29_B_Part_1:Q29_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q31A", Q31_A_Part_1:Q31_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q31B", Q31_B_Part_1:Q31_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q33A", Q33_A_Part_1:Q33_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q33B", Q33_B_Part_1:Q33_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q34A", Q34_A_Part_1:Q34_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q34B", Q34_B_Part_1:Q34_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q35A", Q35_A_Part_1:Q35_A_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q35B", Q35_B_Part_1:Q35_B_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q36", Q36_Part_1:Q36_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q37", Q37_Part_1:Q37_OTHER,
          sep = ",",
          na.rm = TRUE) %>%
    unite("Q39", Q39_Part_1:Q39_OTHER,
          sep = ",",
          na.rm = TRUE)
  
  return(survey)
}

survey <- merge_cols(survey) # merge_cols function call

dim(survey) # dimension of data
{% endhighlight %}



{% highlight text %}
## [1] 20037    48
{% endhighlight %}

We have merge all questions which represents more than one answer columns.

first row contains the survey questions.


{% highlight r %}
# separate questions from dataset
questions <- survey %>%
  filter(row.names(survey) == 1) %>%
  t() # transpose

survey <- survey %>%
  filter(!row.names(survey) == 1)
{% endhighlight %}
  
## 2. Exploratory Analysis

## Data Scientist


{% highlight r %}
data_scientists <- survey %>%
  filter(Q5 == 'Data Scientist')
{% endhighlight %}


### Data Scientist Age distribution


{% highlight r %}
data_scientists %>%
  select(Q1, Q2) %>% # prepare data
  mutate(Q2 = ifelse(Q2 == "Prefer to self-describe" | Q2 == "Prefer not to say" | Q2 == "Nonbinary", "Other", Q2)) %>%
  ggplot(aes(Q1, fill = Q2)) + # create plot
  geom_bar(stat = "count", position = "dodge2") +
  geom_text(stat="count", aes(label =..count..), vjust = -0.01) +
  scale_fill_viridis_d(direction = -1) +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  labs(title = "Data Scientist Age Group",
       subtitle = "# of Data Scientists took kaggle survey, 2020",
       fill = "",
       x = "Age") +
  bbplot::bbc_style() +
  theme(legend.position = "top", 
        legend.justification = "left") +
  guides(fill = guide_legend(reverse = TRUE))
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-5-1.png)



### Most data scientists' educational qualifications?


{% highlight r %}
data_scientists %>%
  select(Q4) %>% # prepare data 
  filter(Q4 != 'NA') %>%
  mutate(Q4 = ifelse(Q4 == "Some college/university study without earning a bachelorâ€™s degree" | Q4 == "No formal education past high school", "None", Q4)) %>%
  mutate(Q4 = str_remove_all(Q4, "degree")) %>%
  add_count(Q4, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), 
         percent = round(count/total*100, digits = 0)) %>%
  filter(Q4 != "I prefer not to answer" & Q4 != "None") %>%
  ggplot(aes("", percent, fill= Q4)) + #Make plot 
  geom_bar(stat = "identity") +
  coord_polar(theta = "y", start = 0) +
  geom_text(aes(label =paste0(percent, "%"),
             family="Helvetica",
             size = 5),  
            position = position_stack(vjust = 0.5)) +
  labs(title = "Data Scientists educational qualification",
       subtitle = "% of degree holders, 2020 kaggle Survey",
       x = "",
       y = "",
       fill = "") +
  bbplot::bbc_style() +
  guides(fill = guide_legend(reverse = TRUE), size = FALSE)
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-6-1.png)


Most of Data Scientists have Masters, Bachelors and Doctoral degrees. 
We can generalize that Data Scientists required one of the above three degrees as this degrees account for 94% of total.


### For how long they are coding?


{% highlight r %}
data_scientists %>%
  select(Q6) %>% # prepare data
  filter(Q6 != 'NA') %>%
  mutate_if(is.character, factor) %>%
  mutate(Q6 = fct_relevel(Q6, "I have never written code", "< 1 years", "1-2 years", "3-5 years", "5-10 years", "10-20 years", "20+ years"),
         Q6 = fct_collapse(Q6, "Never coded" = "I have never written code", "10+ years" = c("10-20 years", "20+ years"))
         ) %>%
  group_by(Q6) %>%
  count() %>%
  ggplot(aes(Q6, n)) +
  geom_col(position="identity", 
           fill="#1380A1") +
  geom_hline(yintercept = 0, size = 1, colour="#333333")  +
  geom_hline(yintercept = 300, size = 1, 
             colour = "red", linetype = "dashed") +
  geom_text(aes(label = n), vjust = 0.01, family="Helvetica", size = 6) +
  geom_label(aes(x = "< 1 years", y = 600, label = "Atleast above 1 year of coding experience must be", family="Helvetica")) +
  labs(title = "Coding Experience") + 
  bbplot::bbc_style() 
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-7-1.png)

Approximately 90% of data scientists have more than 1 year of coding Experience.



{% highlight r %}
data_scientists %>%
  select(Q6) %>% # prepare data
  filter(Q6 != 'NA') %>%
  mutate_if(is.character, factor) %>%
  mutate(Q6 = fct_relevel(Q6, "I have never written code", "< 1 years", "1-2 years", "3-5 years", "5-10 years", "10-20 years", "20+ years"),
         Q6 = fct_collapse(Q6, "Never coded" = "I have never written code", "10+ years" = c("10-20 years", "20+ years"))
         ) %>%
  add_count(Q6, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), percent = count/total*100)
{% endhighlight %}



{% highlight text %}
## # A tibble: 6 x 4
##   Q6          count total percent
##   <fct>       <int> <int>   <dbl>
## 1 5-10 years    584  2659   22.0 
## 2 < 1 years     247  2659    9.29
## 3 3-5 years     743  2659   27.9 
## 4 10+ years     578  2659   21.7 
## 5 1-2 years     460  2659   17.3 
## 6 Never coded    47  2659    1.77
{% endhighlight %}

Coding Experience is must only 47 of the data scientist professional is without any coding experience which account just $1.77%$. At least 1 years of coding experience will increase the chance.

  
### Programming Language used on Regular basis and Recommended.


{% highlight r %}
library(formattable)

data_scientists %>%
  select(Q7) %>% # prepare data
  filter(Q7 != 'NA') %>%
  mutate(Q7 = strsplit(Q7, ",")) %>%
  unnest(Q7) %>%
  add_count(Q7, name = "count") %>%
  unique() %>%
  rename("Programming language" = Q7) %>%
  mutate(total = sum(count), percent = round(count/total*100, 2)) %>%
  arrange(desc(percent)) %>%
  formattable()
{% endhighlight %}


<table class="table table-condensed">
 <thead>
  <tr>
   <th style="text-align:right;"> Programming language </th>
   <th style="text-align:right;"> count </th>
   <th style="text-align:right;"> total </th>
   <th style="text-align:right;"> percent </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> Python </td>
   <td style="text-align:right;"> 2453 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 34.80 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> SQL </td>
   <td style="text-align:right;"> 1473 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 20.90 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> R </td>
   <td style="text-align:right;"> 975 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 13.83 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Bash </td>
   <td style="text-align:right;"> 405 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 5.75 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> C++ </td>
   <td style="text-align:right;"> 323 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 4.58 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Java </td>
   <td style="text-align:right;"> 305 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 4.33 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Javascript </td>
   <td style="text-align:right;"> 290 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 4.11 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> C </td>
   <td style="text-align:right;"> 247 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 3.50 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Other </td>
   <td style="text-align:right;"> 245 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 3.48 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> MATLAB </td>
   <td style="text-align:right;"> 242 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 3.43 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Julia </td>
   <td style="text-align:right;"> 71 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 1.01 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Swift </td>
   <td style="text-align:right;"> 14 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 0.20 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> None </td>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 7048 </td>
   <td style="text-align:right;"> 0.07 </td>
  </tr>
</tbody>
</table>

By far Python, SQL, R are most Important language.
We have to compare to recommended language by data scientists. 



{% highlight r %}
data_scientists %>%
  select(Q8) %>%
  filter(Q8 != 'NA') %>%
  add_count(Q8, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), percent = count/total*100) %>%
  arrange(desc(percent)) %>%
  filter(percent > 1) %>%
  ggplot(aes(x = "", percent, fill = Q8)) +
  geom_bar(stat = "identity", size = 1) +
  coord_polar(theta = "y", start = 0) +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  geom_text(aes(label = paste0(round(percent, 0), "%")),
            position = position_stack(vjust = 0.58),
             family="Helvetica", size = 5) +
  scale_fill_manual(values = c("#FAAB18", "#1380A1","#990000")) +
  bbplot::bbc_style() +
  labs(title = "Recommended Language",
       subtitle = "% of Data Scientist recommended")
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-10-1.png)

By far Python, SQL, R are most used and recommended by Data Scientists.

### Hardware Required on day-to-day basis?

{% highlight r %}
data_scientists %>%
  select(Q11) %>% # prepare data
  filter(Q11 != 'NA') %>%
  add_count(Q11, name = "count") %>%
  unique() %>%
  mutate(Q11 = recode_factor(Q11, "A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)" = "cloud platform", "A personal computer or laptop" = "PC or laptop", "A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)" = "workstation"),
         Q11 = fct_reorder(Q11, count)) %>%
  ggplot(aes(Q11, count)) + # make plot
  geom_col() +
  geom_col(position="identity", 
           fill="#1380A1") +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  geom_text(aes(label = count), vjust = -0.05, 
            family = "Helvetica", size = 6) +
  bbplot::bbc_style()
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-11-1.png)

Most of them required no special hardware to do data related tasks.
Most of the Data Scientists(86% of data scientists) used hardware:
1. Personal Computers(64%)
2. Cloud Platforms(23%)


### Most preferred coding environment? 

{% highlight r %}
data_scientists %>%
  select(Q10) %>% # prepare data
  filter(Q10 != "NA") %>%
  mutate(Q10 = strsplit(Q10, ",")) %>%
  unnest(Q10) %>%
  group_by() %>%
  add_count(Q10, name = "count") %>%
  unique() %>%
  mutate(Q10 = fct_reorder(Q10, count)) %>%
  filter(count > 15) %>%
  ggplot(aes(Q10, count)) +
  geom_col(position = "identity", fill="#1380A1") +
  coord_flip() +
  geom_hline(yintercept = 0, size = 1, colour="#333333") +
  geom_text(aes(label = count), hjust = 1, vjust = 0.5, 
            family = "Helvetica", size = 6, colour = "white") +
  labs(title = "Notebooks",
       subtitle = "# of Data Scientist used Notebooks")+
  bbplot::bbc_style()
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-12-1.png)


1. Colab Notebooks
2. Kaggle Notebooks 

are most preferred notebooks.


### Must know Libraries/Methods ?

#### visualization libraries


{% highlight r %}
# visualization library
data_scientists %>%
  select(Q14) %>% # prepare data
  filter(Q14 != 'NA') %>%
  mutate(Q14 = strsplit(Q14, ",")) %>%
  unnest(Q14) %>%
  add_count(Q14, name = "count") %>%
  mutate(Q14 = fct_reorder(Q14, count)) %>%
  unique() %>%
  ggplot(aes(as.factor(Q14), count, colour = "#FAAB18")) + # make plot
  geom_line(group = 1, size = 1) +
  geom_point(colour = "#333333") +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  geom_text(aes(label = count), vjust = -0.5, colour = "black",
            family = "Helvetica", size = 6) +
  scale_colour_manual(values = "#FAAB18") +
  coord_flip() +
  labs(x = "", 
       y = "",
       title = "Visualization Libraries") +
  theme(legend.position = "none", 
        axis.text = element_text(size= 14, family = "Helvetica", colour = "#333333"), 
        text = element_text(size= 14, family = "Helvetica", colour = "#333333"))
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-13-1.png)


Visualization library curve increases exponential. This libraries are most used one: 
1. Shiny 
2. Ggplot
3. Plotly
4. Seaborn
5. Matplotlib


#### Common Machine Learning Methods used?


{% highlight r %}
ml_library <- as_tibble(gsub("\\s*\\([^\\)]+\\)","",
                   as.character(data_scientists$Q17)
                   ))

# prepare data
ml_library <- ml_library %>%
  mutate(value = strsplit(value, ",")) %>%
  unnest(value) %>%
  add_count(value, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), percent = round((count / total)*100, 0))

# make plot
ml_library %>%
  filter(value != "NA" & percent > 3) %>%
  mutate(value = fct_reorder(value, percent)) %>%
  ggplot(aes("", percent, fill = value)) +
  geom_col() +
  geom_text(aes(label = paste0(percent, "%")), vjust = 0.5, 
            colour = "white", position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y", start = 0) +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  labs(title = "ML Methods",
       x = "",
       y = "",
       fill = "") +
  theme(legend.position = "left",
        axis.text = element_text(size= 14, family = "Helvetica", colour = "#333333"), 
        text = element_text(size= 14, family = "Helvetica", colour = "#333333")) 
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-14-1.png)

Most methods used by data scientists are:
1. Linear or Logistic Regression.
2. Decision Trees or Random Forest
3. Gradient Boosting Machines

more than 50% of data scientists used this ml methods on daily basis.

#### Computer Vision Methods to know?


{% highlight r %}
cv_algo <- as_tibble(gsub("\\s*\\([^\\)]+\\)","",
                   as.character(data_scientists$Q18)
                   ))

# prepare data
cv_algo <- cv_algo %>%
  mutate(value = strsplit(value, ",")) %>%
  unnest(value) %>%
  add_count(value, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), percent = round((count / total)*100, 2)) 
  
# make a table
cv_algo %>%
  arrange(desc(count)) %>%
  formattable()
{% endhighlight %}


<table class="table table-condensed">
 <thead>
  <tr>
   <th style="text-align:right;"> value </th>
   <th style="text-align:right;"> count </th>
   <th style="text-align:right;"> total </th>
   <th style="text-align:right;"> percent </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> Image classification and other general purpose networks </td>
   <td style="text-align:right;"> 679 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 30.06 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> General purpose image/video tools </td>
   <td style="text-align:right;"> 429 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 18.99 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Image segmentation methods </td>
   <td style="text-align:right;"> 396 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 17.53 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Object detection methods </td>
   <td style="text-align:right;"> 387 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 17.13 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> None </td>
   <td style="text-align:right;"> 187 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 8.28 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Generative Networks </td>
   <td style="text-align:right;"> 173 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 7.66 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> Other </td>
   <td style="text-align:right;"> 8 </td>
   <td style="text-align:right;"> 2259 </td>
   <td style="text-align:right;"> 0.35 </td>
  </tr>
</tbody>
</table>

Most important OpenCV methods are:

1. Image classification and other general purpose networks
2. General purpose image/video tools
3. Image segmentation methods
4. Object detection methods

### NLP Methods to know?


{% highlight r %}
require(pack)
nlp <- as_tibble(gsub("\\s*\\([^\\)]+\\)","",
                   as.character(data_scientists$Q19)
                   ))

# prepare data
nlp <- nlp %>%
  mutate(value = strsplit(value, ",")) %>%
  unnest(value) %>%
  add_count(value, name = "count") %>%
  unique() %>%
  mutate(total = sum(count), percent = round((count / total)*100, 2)) 


# make plot
bubbles::bubbles(nlp$percent, nlp$value, color = rainbow(6, alpha=NULL)[6], width=1000, height=900)
{% endhighlight %}



{% highlight text %}
## Error in (function (url = NULL, file = "webshot.png", vwidth = 992, vheight = 744, : webshot.js returned failure value: 1
{% endhighlight %}

Most used Natural language Processing models are:
1. Transformer language models
2. Word embeddings/vectors
3. Encoder-decoder models
4. Contextualized embeddings


### Most famous cloud services among data scientists?


{% highlight r %}
count(data_scientists) 
{% endhighlight %}



{% highlight text %}
## # A tibble: 1 x 1
##       n
##   <int>
## 1  2676
{% endhighlight %}



{% highlight r %}
data_scientists %>%
  select(Q26A) %>%
  filter(Q26A != "") %>%
  summarise(count = n(), total = 2676, percent = count/total*100)
{% endhighlight %}



{% highlight text %}
## # A tibble: 1 x 3
##   count total percent
##   <int> <dbl>   <dbl>
## 1  1772  2676    66.2
{% endhighlight %}



{% highlight r %}
data_scientists %>%
  select(Q26A) %>%
  filter(Q26A != "") %>%
  mutate(Q26A = strsplit(Q26A, ",")) %>%
  unnest(Q26A) %>%
  add_count(Q26A, name = "count") %>%
  unique() %>%
  arrange(desc(count)) %>%
  mutate(total = sum(count), percent = round(count/total*100,0)) %>%
  filter(percent > 2) %>%
  ggplot(aes("", percent, fill = Q26A)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(percent, "%")), 
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  labs(fill = "Cloud Platform") +
  theme(axis.text = element_text(size= 14, family = "Helvetica", colour = "#333333"), 
        text = element_text(size= 14, family = "Helvetica", colour = "#333333"))
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-17-1.png)

Most used cloud-platform by data scientists:
1. AWS
2. GCP
3. Azure 

## Database to used for Big data?


{% highlight r %}
# prepare data
database <- data_scientists %>%
  select(Q29A) %>% 
  filter(Q29A != "") %>%
  mutate(Q29A = strsplit(Q29A, ",")) %>%
  unnest(Q29A) %>%
  add_count(Q29A, name = "count") %>%
  unique() %>%
  arrange(desc(count)) %>%
  mutate(total = sum(count), percent = round(count/total*100,0)) %>%
  mutate(Q29A = fct_reorder(Q29A, percent)) %>%
  filter(percent > 2)
  
ggplot(database, aes(Q29A, percent)) +
  geom_col(fill = ifelse(database$Q29A == "None","#1380A1", "#FAAB18")) +
  geom_text(aes(y = 1,label = paste0(percent, "%")), 
            hjust = 0, vjust = 0.5, 
            colour = ifelse(database$Q29A == "None", "white", "black")) +
  coord_flip() +
  labs(title = "Database") +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  bbplot::bbc_style()
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-18-1.png)

Data Scientists don't have any clear preference in database.

## Most used Bussiness Intelligence software?


{% highlight r %}
data_scientists %>%
  select(Q31A) %>%
  filter(Q31A != "") %>%
  mutate(Q31A = strsplit(Q31A, ",")) %>%
  unnest(Q31A) %>%
  add_count(Q31A, name = "count") %>%
  unique() %>%
  arrange(desc(count)) %>%
  mutate(total = sum(count), percent = round(count/total*100,0)) %>%
  mutate(Q31A = fct_reorder(Q31A, percent)) %>%
  filter(percent > 2) %>%
  ggplot(aes(Q31A, percent)) +
  geom_col(fill = "#990000") +
  geom_text(aes(y = 2,label = paste0(percent, "%")), hjust = 0, vjust = 0.5, colour = "white") +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  bbplot::bbc_style() +
  theme(axis.text.x = element_text(angle = 10, size = 12))
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-19-1.png)

Out of our sample only 60% of data scientists used BI tools. 
Out of them: 
1. Tableau
2. Microsoft Power BI
are most preferred.

### Where most of the data scientists preferred to deploy there work?


{% highlight r %}
# prepare data
deploy <- data_scientists %>%
  select(Q36) %>%
  filter(Q36 != "") %>%
  mutate(Q36 = strsplit(Q36, ",")) %>%
  unnest(Q36) %>%
  add_count(Q36, name = "count") %>%
  unique() %>%
  arrange(desc(count)) %>%
  mutate(Q36 = ifelse(Q36 == "I do not share my work publicly",
                      "No sharing", Q36)) %>%
  mutate_if(is.character, factor) %>%
  mutate(total = sum(count), percent = round(count/total * 100, 0)) %>%
  mutate(Q36 = fct_reorder(Q36, percent))

# make a plot
ggplot(deploy, aes(Q36, percent)) +
  geom_col(fill = ifelse(deploy$Q36 == "No sharing", 
                         "#1380A1","#588300")) +
  geom_text(aes(label = paste0(percent, "%")), 
            hjust = 0.3, vjust = -0.1, family = "Helvetica", size = 5) +
  geom_hline(yintercept = 0, size = 1, colour = "#333333") +
  bbplot::bbc_style() +
  theme(axis.text.x = element_text(angle = 18, size = 12))
{% endhighlight %}

![center](/../figs/2020-12-12-kaggle_survey_2020/unnamed-chunk-20-1.png)


1. Github
2. Kaggle
3. Colab 

are most preferred platform to public show there work.


## Summary

We can conclude from above exploration skills, education, Hardware and  experience required to be a data scientists.
1. **Education**: Most of the employers preferred employee's with Masters degree.
2. **Language to learn** : Python, SQL, R 
3. **Coding Experience**: greater than 1 year
4.**Specific Hardware required**: I don't think so most of them use PC or laptop. I think midrange configuration laptops or PC are sufficient for most of the data scientists tasks.
5. **Must have skills(Knowledge)**: 
       - **visualization Libraries**: Shiny, Ggplot, Plotly, Seaborn, Matplotlib.
       - **ML Methods(Concepts must have)**:  Linear or Logistic Regression, Decision Trees or Random Forest, Gradient Boosting Machines, Neural Networks(CNN, RNN).
       - **Compuer Vision(concepts must have)**: Image classification and other general purpose networks, General purpose image/video tools, Image segmentation methods, Object detection methods.
       - **NLP(concepts must have)**: Transformer language models, Word embeddings/vectors, Encoder-decoder models, Contextualized embeddings
       -**BI software to know**: Tableau, Microsoft Power BI.
6. **Notebooks used and Platform to deploy Work**
    - **Notebooks(should be familiar with)** Colab,Kaggle 
    - **Platform to deploy to show skills(work)**: Github, Kaggle, Colab.


(**Note**: data scientist position is a mixture of a lot of roles

![Source: Jason Jung](https://miro.medium.com/max/2400/1*bw6Q4AkG9l6vZqaRgOAkfA.png)

)

Reference:
![Machine Learning Engineer vs Data Scientist (Is Data Science Over?)](https://towardsdatascience.com/mlevsds-3c89425baabb)
Reference:

1. ![Machine Learning Engineer vs Data Scientist (Is Data Science Over?)](https://towardsdatascience.com/mlevsds-3c89425baabb)
